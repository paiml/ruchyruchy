// COMPILED-INST-001: Minimal Ruchy Compiler Prototype
//
// This is a PROTOTYPE to validate the approach before filing production Ruchy ticket.
// It demonstrates AST-level profiling instrumentation with <1% overhead target.
//
// GREEN Phase - Minimal implementation to make tests pass

use std::env;
use std::fs;
use std::process::{exit, Command};

const VERSION: &str = env!("CARGO_PKG_VERSION");

fn main() {
    let args: Vec<String> = env::args().collect();

    if args.len() < 2 {
        print_usage();
        exit(1);
    }

    match args[1].as_str() {
        "compile" => handle_compile(&args[2..]),
        "profile" => handle_profile(&args[2..]),
        "analyze" => handle_analyze(&args[2..]),
        "version" | "--version" | "-v" => {
            println!("ruchy (RuchyRuchy prototype) {}", VERSION);
            exit(0);
        }
        "help" | "--help" | "-h" => {
            print_usage();
            exit(0);
        }
        _ => {
            eprintln!("Unknown subcommand: {}", args[1]);
            print_usage();
            exit(1);
        }
    }
}

fn print_usage() {
    eprintln!("ruchy (RuchyRuchy COMPILED-INST-001/002/003 Prototype)");
    eprintln!();
    eprintln!("USAGE:");
    eprintln!("    ruchy compile [--instrument] <file.ruchy> --output <binary>");
    eprintln!("    ruchy profile [--counters=<list>] [--output=<json>] <binary>");
    eprintln!(
        "    ruchy analyze [--size|--symbols|--startup|--relocations|--optimize|--format] <binary>"
    );
    eprintln!();
    eprintln!("SUBCOMMANDS:");
    eprintln!("    compile     Compile Ruchy source to binary");
    eprintln!("    profile     Profile compiled binary with hardware counters");
    eprintln!("    analyze     Analyze compiled binary (size, symbols, performance)");
    eprintln!();
    eprintln!("COMPILE FLAGS:");
    eprintln!("    --instrument    Enable AST-level profiling instrumentation");
    eprintln!();
    eprintln!("PROFILE FLAGS:");
    eprintln!(
        "    --counters=<list>     Hardware counters (cpu_cycles,cache_misses,branch_misses)"
    );
    eprintln!("    --output=<json>       Output JSON profile data");
    eprintln!("    --flame-graph=<svg>   Generate flame graph SVG");
    eprintln!("    --hotspots=<N>        Identify top N hotspot functions");
    eprintln!("    --sampling-rate=<Hz>  Sampling frequency (default: 1000Hz)");
    eprintln!();
    eprintln!("ANALYZE FLAGS:");
    eprintln!("    --size          Binary size breakdown by section");
    eprintln!("    --symbols       Symbol table analysis");
    eprintln!("    --startup       Startup time profiling");
    eprintln!("    --relocations   Relocation overhead analysis");
    eprintln!("    --optimize      Optimization recommendations");
    eprintln!("    --format        Binary format detection");
    eprintln!("    --output=<json> Output JSON analysis data");
}

fn handle_compile(args: &[String]) {
    let mut instrument = false;
    let mut input_file: Option<String> = None;
    let mut output_file: Option<String> = None;

    let mut i = 0;
    while i < args.len() {
        let arg = &args[i];

        if arg == "--instrument" {
            instrument = true;
            i += 1;
        } else if arg == "--output" {
            // Handle --output /path format
            if i + 1 < args.len() {
                output_file = Some(args[i + 1].clone());
                i += 2;
            } else {
                eprintln!("Error: --output requires a value");
                exit(1);
            }
        } else if arg.starts_with("--output=") {
            // Handle --output=/path format
            output_file = Some(arg.strip_prefix("--output=").unwrap().to_string());
            i += 1;
        } else if arg.ends_with(".ruchy") {
            input_file = Some(arg.to_string());
            i += 1;
        } else {
            eprintln!("Unknown argument: {}", arg);
            exit(1);
        }
    }

    let input_file = input_file.unwrap_or_else(|| {
        eprintln!("Error: No input file specified");
        exit(1);
    });

    let output_file = output_file.unwrap_or_else(|| {
        eprintln!("Error: --output is required");
        exit(1);
    });

    // Read Ruchy source
    let ruchy_source = fs::read_to_string(&input_file).unwrap_or_else(|e| {
        eprintln!("Error reading {}: {}", input_file, e);
        exit(1);
    });

    // Compile
    if instrument {
        compile_instrumented(&ruchy_source, &output_file);
    } else {
        compile_normal(&ruchy_source, &output_file);
    }
}

fn compile_normal(ruchy_source: &str, output_file: &str) {
    let rust_code = transform_ruchy_to_rust(ruchy_source);
    compile_rust(&rust_code, output_file);
    eprintln!("✅ Compiled: {}", output_file);
}

fn compile_instrumented(ruchy_source: &str, output_file: &str) {
    let mut rust_code = String::new();

    // Header
    rust_code.push_str("// Generated by RuchyRuchy (COMPILED-INST-001)\n\n");

    // Add profiler runtime (simplified - no complex escaping)
    rust_code.push_str(&generate_profiler_runtime());

    // Transform Ruchy to Rust
    let mut transformed = transform_ruchy_to_rust(ruchy_source);

    // Instrument all functions with ProfilerGuard
    transformed = instrument_functions(&transformed);

    // Instrument loops with iteration tracking
    transformed = instrument_loops(&transformed);

    // Instrument branches with taken/not-taken tracking
    transformed = instrument_branches(&transformed);

    // Instrument main function with init/export calls
    transformed = instrument_main(&transformed);

    rust_code.push_str(&transformed);

    compile_rust(&rust_code, output_file);
    eprintln!("✅ Compiled with instrumentation: {}", output_file);
}

fn transform_ruchy_to_rust(source: &str) -> String {
    let mut result = source.to_string();

    // Transform function keyword
    result = result.replace("fun ", "fn ");

    // Transform for loops: for i in 0..N → for i in 0..N (same in Rust)
    // Ruchy uses same syntax as Rust for ranges

    // Transform println/print calls
    // This is a simplified approach - full implementation would need proper parsing
    result = transform_println_calls(&result);

    result
}

fn transform_println_calls(source: &str) -> String {
    // Find all println( and convert to println!(...)
    // If arg is not a string literal, wrap with "{}",
    let mut result = String::new();
    let mut chars = source.chars().peekable();

    while let Some(c) = chars.next() {
        result.push(c);

        // Check if we just wrote "println("
        if result.ends_with("println(") {
            // Replace the last "println(" with "println!("
            let len = result.len();
            result.truncate(len - 8); // Remove "println("
            result.push_str("println!(");

            // Now check if next char is a quote
            if matches!(chars.peek(), Some('"')) {
                // String literal - just pass through
                continue;
            } else {
                // Non-string - wrap with "{}",
                result.push_str("\"{}\", ");
            }
        }
    }

    result
}

fn instrument_functions(code: &str) -> String {
    // Insert ProfilerGuard at the beginning of each function
    // Simple approach: find "fn <name>(...) {" and insert guard
    let mut result = String::new();
    let lines: Vec<&str> = code.lines().collect();

    for line in lines {
        result.push_str(line);
        result.push('\n');

        // Check if this line declares a function
        if line.trim_start().starts_with("fn ") && line.contains('{') {
            // Extract function name
            if let Some(name_start) = line.find("fn ").map(|p| p + 3) {
                if let Some(name_end) = line[name_start..].find('(') {
                    let function_name = &line[name_start..name_start + name_end].trim();

                    // Add profiler guard (skip main, it's handled separately)
                    if *function_name != "main" {
                        result.push_str(&format!(
                            "    let _profiler_guard = ProfilerGuard::new(\"{}\");\n",
                            function_name
                        ));
                    }
                }
            }
        }
    }

    result
}

fn instrument_loops(code: &str) -> String {
    // Insert loop iteration tracking for each for loop
    // Pattern: for VAR in RANGE { → for VAR in RANGE { record_loop_iter(...);
    let mut result = String::new();
    let mut lines: Vec<&str> = code.lines().collect();
    let mut loop_id = 0;

    for (line_num, line) in lines.iter().enumerate() {
        result.push_str(line);
        result.push('\n');

        // Detect for loops
        if line.trim_start().starts_with("for ") && line.contains('{') {
            // Add loop iteration tracking at the start of the loop body
            let location = format!("loop_{}", loop_id);
            result.push_str(&format!(
                "        record_loop_iteration(\"{}\");\n",
                location
            ));
            loop_id += 1;
        }
    }

    result
}

fn instrument_branches(code: &str) -> String {
    // Insert branch tracking for if statements
    // Pattern: if CONDITION { → if record_branch("branch_N", CONDITION) {
    let mut result = String::new();
    let mut branch_id = 0;
    let mut chars = code.chars().peekable();

    while let Some(c) = chars.next() {
        result.push(c);

        // Look for "if " pattern
        if result.ends_with("if ") {
            // Collect the condition until we hit '{'
            let mut condition = String::new();
            let mut depth = 0;

            while let Some(ch) = chars.peek() {
                if *ch == '(' {
                    depth += 1;
                    condition.push(chars.next().unwrap());
                } else if *ch == ')' {
                    depth -= 1;
                    condition.push(chars.next().unwrap());
                } else if *ch == '{' && depth == 0 {
                    // Found the opening brace
                    break;
                } else {
                    condition.push(chars.next().unwrap());
                }
            }

            let condition = condition.trim();
            if !condition.is_empty() {
                // Wrap condition with record_branch
                result.push_str(&format!(
                    "record_branch(\"branch_{}\", {}) ",
                    branch_id, condition
                ));
                branch_id += 1;
            } else {
                result.push_str(condition);
            }
        }
    }

    result
}

fn instrument_main(code: &str) -> String {
    // Find main() and add profiler calls
    if let Some(main_pos) = code.find("fn main()") {
        if let Some(brace_pos) = code[main_pos..].find('{').map(|p| main_pos + p) {
            let mut result = code[..brace_pos + 1].to_string();
            result.push_str("\n    init_profiler();");
            result.push_str(&code[brace_pos + 1..]);

            // Add finalize before last closing brace
            if let Some(last_brace) = result.rfind('}') {
                result.insert_str(last_brace, "\n    export_profile_data();\n");
            }

            return result;
        }
    }
    code.to_string()
}

fn generate_profiler_runtime() -> String {
    // Generate profiler runtime code programmatically (no complex string templates)
    let mut code = String::new();

    // Imports
    code.push_str("use std::collections::HashMap;\n");
    code.push_str("use std::sync::atomic::{AtomicBool, Ordering};\n");
    code.push_str("use std::cell::RefCell;\n");
    code.push_str("use std::time::Instant;\n\n");

    // Global state
    code.push_str("static PROFILER_ENABLED: AtomicBool = AtomicBool::new(false);\n\n");

    // Thread-local data
    code.push_str("thread_local! {\n");
    code.push_str(
        "    static PROFILER_DATA: RefCell<ProfilerData> = RefCell::new(ProfilerData::new());\n",
    );
    code.push_str("    static START_TIME: Instant = Instant::now();\n");
    code.push_str("}\n\n");

    // Data structures
    code.push_str("#[derive(Debug, Clone)]\n");
    code.push_str("struct ProfilerData {\n");
    code.push_str("    functions: HashMap<String, FunctionStats>,\n");
    code.push_str("    loops: HashMap<String, LoopStats>,\n");
    code.push_str("    branches: HashMap<String, BranchStats>,\n");
    code.push_str("}\n\n");

    code.push_str("impl ProfilerData {\n");
    code.push_str("    fn new() -> Self {\n");
    code.push_str("        Self { functions: HashMap::new(), loops: HashMap::new(), branches: HashMap::new() }\n");
    code.push_str("    }\n");
    code.push_str("}\n\n");

    code.push_str("#[derive(Debug, Clone)]\n");
    code.push_str("struct FunctionStats {\n");
    code.push_str("    calls: u64,\n");
    code.push_str("    total_time_ns: u64,\n");
    code.push_str("}\n\n");

    code.push_str("impl FunctionStats {\n");
    code.push_str("    fn new() -> Self {\n");
    code.push_str("        Self { calls: 0, total_time_ns: 0 }\n");
    code.push_str("    }\n");
    code.push_str("}\n\n");

    code.push_str("#[derive(Debug, Clone)]\n");
    code.push_str("struct LoopStats {\n");
    code.push_str("    iterations: u64,\n");
    code.push_str("}\n\n");

    code.push_str("impl LoopStats {\n");
    code.push_str("    fn new() -> Self {\n");
    code.push_str("        Self { iterations: 0 }\n");
    code.push_str("    }\n");
    code.push_str("}\n\n");

    code.push_str("#[derive(Debug, Clone)]\n");
    code.push_str("struct BranchStats {\n");
    code.push_str("    taken: u64,\n");
    code.push_str("    not_taken: u64,\n");
    code.push_str("}\n\n");

    code.push_str("impl BranchStats {\n");
    code.push_str("    fn new() -> Self {\n");
    code.push_str("        Self { taken: 0, not_taken: 0 }\n");
    code.push_str("    }\n");
    code.push_str("}\n\n");

    // ProfilerGuard for RAII function timing
    code.push_str("struct ProfilerGuard {\n");
    code.push_str("    function_name: &'static str,\n");
    code.push_str("    start_time: Instant,\n");
    code.push_str("}\n\n");

    code.push_str("impl ProfilerGuard {\n");
    code.push_str("    fn new(function_name: &'static str) -> Self {\n");
    code.push_str("        if !PROFILER_ENABLED.load(Ordering::Relaxed) {\n");
    code.push_str(
        "            return Self { function_name, start_time: START_TIME.with(|t| *t) };\n",
    );
    code.push_str("        }\n");
    code.push_str("        PROFILER_DATA.with(|data| {\n");
    code.push_str("            let mut d = data.borrow_mut();\n");
    code.push_str("            d.functions.entry(function_name.to_string()).or_insert(FunctionStats::new()).calls += 1;\n");
    code.push_str("        });\n");
    code.push_str("        Self { function_name, start_time: Instant::now() }\n");
    code.push_str("    }\n");
    code.push_str("}\n\n");

    code.push_str("impl Drop for ProfilerGuard {\n");
    code.push_str("    fn drop(&mut self) {\n");
    code.push_str("        if !PROFILER_ENABLED.load(Ordering::Relaxed) { return; }\n");
    code.push_str("        let elapsed = self.start_time.elapsed().as_nanos() as u64;\n");
    code.push_str("        PROFILER_DATA.with(|data| {\n");
    code.push_str("            let mut d = data.borrow_mut();\n");
    code.push_str("            if let Some(stats) = d.functions.get_mut(self.function_name) {\n");
    code.push_str("                stats.total_time_ns += elapsed;\n");
    code.push_str("            }\n");
    code.push_str("        });\n");
    code.push_str("    }\n");
    code.push_str("}\n\n");

    // Init function
    code.push_str("fn init_profiler() {\n");
    code.push_str("    if std::env::var(\"RUCHY_PROFILE\").unwrap_or_default() == \"1\" {\n");
    code.push_str("        PROFILER_ENABLED.store(true, Ordering::Relaxed);\n");
    code.push_str("        eprintln!(\"[PROFILER] Enabled\");\n");
    code.push_str("    }\n");
    code.push_str("}\n\n");

    // Loop iteration recording
    code.push_str("fn record_loop_iteration(location: &str) {\n");
    code.push_str("    if !PROFILER_ENABLED.load(Ordering::Relaxed) { return; }\n");
    code.push_str("    PROFILER_DATA.with(|data| {\n");
    code.push_str("        let mut d = data.borrow_mut();\n");
    code.push_str("        d.loops.entry(location.to_string()).or_insert(LoopStats::new()).iterations += 1;\n");
    code.push_str("    });\n");
    code.push_str("}\n\n");

    // Branch recording
    code.push_str("fn record_branch(location: &str, outcome: bool) -> bool {\n");
    code.push_str("    if !PROFILER_ENABLED.load(Ordering::Relaxed) { return outcome; }\n");
    code.push_str("    PROFILER_DATA.with(|data| {\n");
    code.push_str("        let mut d = data.borrow_mut();\n");
    code.push_str("        let stats = d.branches.entry(location.to_string()).or_insert(BranchStats::new());\n");
    code.push_str("        if outcome { stats.taken += 1; } else { stats.not_taken += 1; }\n");
    code.push_str("    });\n");
    code.push_str("    outcome\n");
    code.push_str("}\n\n");

    // Export function (simplified JSON generation)
    code.push_str("fn export_profile_data() {\n");
    code.push_str("    if !PROFILER_ENABLED.load(Ordering::Relaxed) { return; }\n\n");
    code.push_str("    let output_path = std::env::var(\"RUCHY_PROFILE_OUTPUT\")\n");
    code.push_str("        .unwrap_or_else(|_| \"profile.json\".to_string());\n\n");
    code.push_str("    let data = PROFILER_DATA.with(|d| d.borrow().clone());\n\n");
    code.push_str("    let mut json = String::from(\"{\\n\");\n");
    code.push_str("    json.push_str(\"  \\\"version\\\": \\\"1.0\\\",\\n\");\n");
    code.push_str("    let timestamp = std::time::SystemTime::now().duration_since(std::time::UNIX_EPOCH).unwrap().as_secs();\n");
    code.push_str("    json.push_str(&format!(\"  \\\"timestamp\\\": {},\\n\", timestamp));\n");
    code.push_str("    let binary = std::env::current_exe().ok().map(|p| p.display().to_string()).unwrap_or_else(|| ");
    code.push('"');
    code.push_str("unknown");
    code.push('"');
    code.push_str(".to_string());\n");
    code.push_str("    json.push_str(&format!(\"  \\\"binary\\\": \\\"{}\\\",\\n\", binary));\n");
    code.push_str("    json.push_str(\"  \\\"functions\\\": [\\n\");\n\n");
    code.push_str("    let mut first = true;\n");
    code.push_str("    for (name, stats) in &data.functions {\n");
    code.push_str("        if !first { json.push_str(\",\\n\"); }\n");
    code.push_str("        first = false;\n");
    code.push_str("        let avg = if stats.calls > 0 { stats.total_time_ns as f64 / stats.calls as f64 } else { 0.0 };\n");
    code.push_str(
        "        json.push_str(&format!(\"    {{\\n      \\\"name\\\": \\\"{}\\\",\\n\", name));\n",
    );
    code.push_str(
        "        json.push_str(&format!(\"      \\\"calls\\\": {},\\n\", stats.calls));\n",
    );
    code.push_str("        json.push_str(&format!(\"      \\\"total_time_ns\\\": {},\\n\", stats.total_time_ns));\n");
    code.push_str(
        "        json.push_str(&format!(\"      \\\"avg_time_ns\\\": {:.2},\\n\", avg));\n",
    );
    code.push_str("        json.push_str(&format!(\"      \\\"min_time_ns\\\": {},\\n\", 0));\n");
    code.push_str("        json.push_str(&format!(\"      \\\"max_time_ns\\\": {}\\n\", stats.total_time_ns));\n");
    code.push_str("        json.push_str(\"    }\");\n");
    code.push_str("    }\n\n");
    code.push_str("    json.push_str(\"\\n  ],\\n\");\n");
    code.push_str("    json.push_str(\"  \\\"loops\\\": [\\n\");\n\n");
    code.push_str("    let mut first_loop = true;\n");
    code.push_str("    for (location, stats) in &data.loops {\n");
    code.push_str("        if !first_loop { json.push_str(\",\\n\"); }\n");
    code.push_str("        first_loop = false;\n");
    code.push_str("        json.push_str(&format!(\"    {{\\n      \\\"location\\\": \\\"{}\\\",\\n\", location));\n");
    code.push_str(
        "        json.push_str(&format!(\"      \\\"iterations\\\": {}\\n\", stats.iterations));\n",
    );
    code.push_str("        json.push_str(\"    }\");\n");
    code.push_str("    }\n\n");
    code.push_str("    json.push_str(\"\\n  ],\\n\");\n");
    code.push_str("    json.push_str(\"  \\\"branches\\\": [\\n\");\n\n");
    code.push_str("    let mut first_branch = true;\n");
    code.push_str("    for (location, stats) in &data.branches {\n");
    code.push_str("        if !first_branch { json.push_str(\",\\n\"); }\n");
    code.push_str("        first_branch = false;\n");
    code.push_str("        let total = stats.taken + stats.not_taken;\n");
    code.push_str("        let prediction_rate = if total > 0 { stats.taken as f64 / total as f64 } else { 0.0 };\n");
    code.push_str("        json.push_str(&format!(\"    {{\\n      \\\"location\\\": \\\"{}\\\",\\n\", location));\n");
    code.push_str(
        "        json.push_str(&format!(\"      \\\"taken\\\": {},\\n\", stats.taken));\n",
    );
    code.push_str(
        "        json.push_str(&format!(\"      \\\"not_taken\\\": {},\\n\", stats.not_taken));\n",
    );
    code.push_str("        json.push_str(&format!(\"      \\\"prediction_rate\\\": {:.5}\\n\", prediction_rate));\n");
    code.push_str("        json.push_str(\"    }\");\n");
    code.push_str("    }\n\n");
    code.push_str("    json.push_str(\"\\n  ],\\n\");\n");
    code.push_str("    json.push_str(\"  \\\"allocations\\\": {\\\"total_allocs\\\": 0, \\\"total_bytes\\\": 0, \\\"peak_memory_bytes\\\": 0, \\\"by_size\\\": {\\\"small\\\": {\\\"count\\\": 0, \\\"bytes\\\": 0}, \\\"medium\\\": {\\\"count\\\": 0, \\\"bytes\\\": 0}, \\\"large\\\": {\\\"count\\\": 0, \\\"bytes\\\": 0}}},\\n\");\n");
    code.push_str("    json.push_str(\"  \\\"statistics\\\": {\\\"total_runtime_ns\\\": 0, \\\"instrumentation_overhead_percent\\\": 0.0}\\n\");\n");
    code.push_str("    json.push_str(\"}\\n\");\n\n");
    code.push_str("    std::fs::write(&output_path, json).expect(\"Failed to write profile\");\n");
    code.push_str("    eprintln!(\"[PROFILER] Exported to: {}\", output_path);\n");
    code.push_str("}\n\n");

    code
}

fn compile_rust(rust_code: &str, output_file: &str) {
    let temp_rust = format!("{}.rs", output_file);
    fs::write(&temp_rust, rust_code).unwrap_or_else(|e| {
        eprintln!("Error writing Rust file: {}", e);
        exit(1);
    });

    let output = Command::new("rustc")
        .arg(&temp_rust)
        .arg("-o")
        .arg(output_file)
        .arg("-C")
        .arg("opt-level=3")
        .arg("-A")
        .arg("warnings")
        .output()
        .unwrap_or_else(|e| {
            eprintln!("Error running rustc: {}", e);
            exit(1);
        });

    if !output.status.success() {
        eprintln!("Compilation failed:");
        eprintln!("{}", String::from_utf8_lossy(&output.stderr));
        fs::remove_file(&temp_rust).ok();
        exit(1);
    }

    fs::remove_file(&temp_rust).ok();
}

fn handle_profile(args: &[String]) {
    #[cfg(not(feature = "profiling"))]
    {
        eprintln!("Error: profiling feature not enabled");
        eprintln!("Rebuild with: cargo build --features profiling --bin ruchy --release");
        exit(1);
    }

    #[cfg(feature = "profiling")]
    {
        use std::time::Instant;

        let mut counters: Vec<String> = vec!["cpu_cycles".to_string()];
        let mut output_json: Option<String> = None;
        let mut flame_graph_svg: Option<String> = None;
        let mut hotspots_count: Option<usize> = None;
        let mut sampling_rate: u64 = 1000; // Default 1000Hz
        let mut binary_path: Option<String> = None;

        let mut i = 0;
        while i < args.len() {
            let arg = &args[i];

            if arg.starts_with("--counters=") {
                let counter_str = arg.strip_prefix("--counters=").unwrap();
                counters = counter_str
                    .split(',')
                    .map(|s| s.trim().to_string())
                    .collect();
                i += 1;
            } else if arg.starts_with("--output=") {
                output_json = Some(arg.strip_prefix("--output=").unwrap().to_string());
                i += 1;
            } else if arg.starts_with("--flame-graph=") {
                flame_graph_svg = Some(arg.strip_prefix("--flame-graph=").unwrap().to_string());
                i += 1;
            } else if arg.starts_with("--hotspots=") {
                let count_str = arg.strip_prefix("--hotspots=").unwrap();
                hotspots_count = Some(count_str.parse().unwrap_or_else(|_| {
                    eprintln!("Error: --hotspots must be a number");
                    exit(1);
                }));
                i += 1;
            } else if arg.starts_with("--sampling-rate=") {
                let rate_str = arg.strip_prefix("--sampling-rate=").unwrap();
                sampling_rate = rate_str.parse().unwrap_or_else(|_| {
                    eprintln!("Error: --sampling-rate must be a number");
                    exit(1);
                });
                i += 1;
            } else if !arg.starts_with("--") {
                binary_path = Some(arg.to_string());
                i += 1;
            } else {
                eprintln!("Unknown argument: {}", arg);
                exit(1);
            }
        }

        let binary_path = binary_path.unwrap_or_else(|| {
            eprintln!("Error: No binary path specified");
            exit(1);
        });

        // Initialize profiler from DEBUGGER-016
        use ruchyruchy::profiling::Profiler;

        eprintln!("[PROFILE] Starting profiler at {}Hz...", sampling_rate);
        eprintln!("[PROFILE] Counters: {}", counters.join(", "));

        let mut profiler = match Profiler::new() {
            Ok(p) => p,
            Err(e) => {
                eprintln!("Error initializing profiler: {}", e);
                eprintln!("Note: Profiling requires root or CAP_PERFMON capability");
                eprintln!(
                    "Try: sudo -E {} profile --output=profile.json {}",
                    env::args().next().unwrap(),
                    binary_path
                );
                exit(1);
            }
        };

        // Start profiling
        profiler.start().unwrap_or_else(|e| {
            eprintln!("Error starting profiler: {}", e);
            exit(1);
        });

        // Run the binary
        let run_start = Instant::now();
        let output = Command::new(&binary_path).output().unwrap_or_else(|e| {
            eprintln!("Error running {}: {}", binary_path, e);
            exit(1);
        });
        let run_duration = run_start.elapsed();

        // Stop profiling
        profiler.stop().unwrap_or_else(|e| {
            eprintln!("Error stopping profiler: {}", e);
            exit(1);
        });

        eprintln!(
            "[PROFILE] Binary completed in {:.3}s",
            run_duration.as_secs_f64()
        );

        // Collect samples
        let samples = profiler.collect_samples().unwrap_or_else(|e| {
            eprintln!("Error collecting samples: {}", e);
            exit(1);
        });

        eprintln!("[PROFILE] Collected {} samples", samples.len());

        // Generate JSON output
        if let Some(ref output_path) = output_json {
            generate_profile_json(&samples, &counters, &binary_path, output_path);
            eprintln!("[PROFILE] Wrote profile to: {}", output_path);
        }

        // Generate flame graph
        if let Some(svg_path) = flame_graph_svg {
            use ruchyruchy::profiling::FlameGraph;
            let flame_graph = FlameGraph::from_samples(&samples);
            let flamegraph_data = flame_graph.to_string();
            fs::write(&svg_path, flamegraph_data).unwrap_or_else(|e| {
                eprintln!("Error writing flame graph: {}", e);
                exit(1);
            });
            eprintln!("[PROFILE] Wrote flame graph to: {}", svg_path);
        }

        // Generate hotspots
        if let Some(count) = hotspots_count {
            use ruchyruchy::profiling::Hotspot;
            let hotspots = Hotspot::analyze(&samples, count);

            if let Some(output_path) = output_json.as_ref() {
                // Already generated JSON above, append hotspots
                let hotspot_path = output_path.replace(".json", "_hotspots.json");

                // Manually generate JSON (HotspotEntry doesn't derive Serialize)
                let mut json = String::from("{\n  \"hotspots\": [\n");
                for (i, entry) in hotspots.iter().enumerate() {
                    json.push_str("    {\n");
                    json.push_str(&format!("      \"function\": \"{}\",\n", entry.function));
                    json.push_str(&format!("      \"samples\": {},\n", entry.count));
                    json.push_str(&format!("      \"percentage\": {:.2}\n", entry.percentage));
                    json.push_str("    }");
                    if i < hotspots.len() - 1 {
                        json.push_str(",");
                    }
                    json.push_str("\n");
                }
                json.push_str("  ]\n}\n");

                fs::write(&hotspot_path, json).unwrap_or_else(|e| {
                    eprintln!("Error writing hotspots: {}", e);
                    exit(1);
                });
                eprintln!("[PROFILE] Wrote hotspots to: {}", hotspot_path);
            }
        }

        // Print binary output
        if output.status.success() {
            println!("{}", String::from_utf8_lossy(&output.stdout));
        } else {
            eprintln!("Binary exited with error:");
            eprintln!("{}", String::from_utf8_lossy(&output.stderr));
            exit(output.status.code().unwrap_or(1));
        }
    }
}

#[cfg(feature = "profiling")]
fn generate_profile_json(
    samples: &[ruchyruchy::profiling::Sample],
    counters: &[String],
    binary_path: &str,
    output_path: &str,
) {
    use std::collections::HashMap;

    let mut json = String::new();
    json.push_str("{\n");
    json.push_str(&format!("  \"version\": \"1.0\",\n"));
    json.push_str(&format!(
        "  \"timestamp\": {},\n",
        std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap()
            .as_secs()
    ));
    json.push_str(&format!("  \"binary\": \"{}\",\n", binary_path));
    json.push_str("  \"counters\": [\n");

    // Aggregate samples by instruction pointer (function)
    let mut function_samples: HashMap<u64, usize> = HashMap::new();
    for sample in samples {
        *function_samples.entry(sample.ip).or_insert(0) += 1;
    }

    // For each counter, generate data
    for (idx, counter_name) in counters.iter().enumerate() {
        json.push_str("    {\n");
        json.push_str(&format!("      \"name\": \"{}\",\n", counter_name));
        json.push_str(&format!("      \"total_samples\": {},\n", samples.len()));
        json.push_str("      \"functions\": [\n");

        // Sort functions by sample count
        let mut sorted_functions: Vec<_> = function_samples.iter().collect();
        sorted_functions.sort_by(|a, b| b.1.cmp(a.1));

        for (i, (ip, count)) in sorted_functions.iter().enumerate() {
            json.push_str("        {\n");
            json.push_str(&format!("          \"address\": \"0x{:x}\",\n", ip));
            json.push_str(&format!("          \"samples\": {},\n", count));
            json.push_str(&format!(
                "          \"percentage\": {:.2}\n",
                (**count as f64 / samples.len() as f64) * 100.0
            ));
            json.push_str("        }");
            if i < sorted_functions.len() - 1 {
                json.push_str(",");
            }
            json.push_str("\n");
        }

        json.push_str("      ]\n");
        json.push_str("    }");
        if idx < counters.len() - 1 {
            json.push_str(",");
        }
        json.push_str("\n");
    }

    json.push_str("  ]");

    // Derived metrics (placeholder for now)
    json.push_str("  \"derived_metrics\": {\n");
    json.push_str("    \"ipc\": 0.0,\n");
    json.push_str("    \"cache_miss_rate\": 0.0,\n");
    json.push_str("    \"branch_miss_rate\": 0.0\n");
    json.push_str("  }\n");

    json.push_str("}\n");

    fs::write(output_path, json).unwrap_or_else(|e| {
        eprintln!("Error writing JSON: {}", e);
        exit(1);
    });
}

fn handle_analyze(args: &[String]) {
    use goblin::elf::Elf;
    use goblin::Object;
    use std::time::Instant;

    let mut analyze_size = false;
    let mut analyze_symbols = false;
    let mut analyze_startup = false;
    let mut analyze_relocations = false;
    let mut analyze_optimize = false;
    let mut analyze_format = false;
    let mut output_json: Option<String> = None;
    let mut binary_path: Option<String> = None;

    let mut i = 0;
    while i < args.len() {
        let arg = &args[i];

        match arg.as_str() {
            "--size" => analyze_size = true,
            "--symbols" => analyze_symbols = true,
            "--startup" => analyze_startup = true,
            "--relocations" => analyze_relocations = true,
            "--optimize" => analyze_optimize = true,
            "--format" => analyze_format = true,
            _ if arg.starts_with("--output=") => {
                output_json = Some(arg.strip_prefix("--output=").unwrap().to_string());
            }
            _ if !arg.starts_with("--") => {
                binary_path = Some(arg.to_string());
            }
            _ => {
                eprintln!("Unknown argument: {}", arg);
                exit(1);
            }
        }
        i += 1;
    }

    let binary_path = binary_path.unwrap_or_else(|| {
        eprintln!("Error: No binary path specified");
        exit(1);
    });

    // Read binary file
    let binary_data = fs::read(&binary_path).unwrap_or_else(|e| {
        eprintln!("Error reading {}: {}", binary_path, e);
        exit(1);
    });

    // Parse binary format
    let object = Object::parse(&binary_data).unwrap_or_else(|e| {
        eprintln!("Error parsing binary: {}", e);
        exit(1);
    });

    // Start building JSON output
    let mut json = String::new();
    json.push_str("{\n");
    json.push_str(&format!("  \"binary\": \"{}\",\n", binary_path));
    json.push_str(&format!(
        "  \"timestamp\": {},\n",
        std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap()
            .as_secs()
    ));

    match object {
        Object::Elf(elf) => {
            json.push_str("  \"format\": \"ELF\",\n");

            // Count how many sections we'll output
            let mut sections_to_output = Vec::new();
            if analyze_format {
                sections_to_output.push("format");
            }
            if analyze_size {
                sections_to_output.push("size");
            }
            if analyze_symbols {
                sections_to_output.push("symbols");
            }
            if analyze_relocations {
                sections_to_output.push("relocations");
            }
            if analyze_optimize {
                sections_to_output.push("optimize");
            }
            if analyze_startup {
                sections_to_output.push("startup");
            }

            let mut sections_done = 0;
            let total_sections = sections_to_output.len();

            // Format detection
            if analyze_format {
                json.push_str("  \"format_details\": {\n");
                json.push_str(&format!(
                    "    \"class\": \"{}\",\n",
                    if elf.is_64 { "64-bit" } else { "32-bit" }
                ));
                json.push_str(&format!(
                    "    \"endian\": \"{}\",\n",
                    if elf.little_endian { "little" } else { "big" }
                ));
                json.push_str(&format!("    \"machine\": {}\n", elf.header.e_machine));
                json.push_str("  }");
                sections_done += 1;
                if sections_done < total_sections {
                    json.push_str(",\n");
                } else {
                    json.push_str("\n");
                }
            }

            // Size analysis
            if analyze_size {
                analyze_elf_size(&elf, &binary_data, &mut json);
                sections_done += 1;
                if sections_done < total_sections {
                    json.push_str(",\n");
                } else {
                    json.push_str("\n");
                }
            }

            // Symbol table analysis
            if analyze_symbols {
                analyze_elf_symbols(&elf, &mut json);
                sections_done += 1;
                if sections_done < total_sections {
                    json.push_str(",\n");
                } else {
                    json.push_str("\n");
                }
            }

            // Relocation analysis
            if analyze_relocations {
                analyze_elf_relocations(&elf, &mut json);
                sections_done += 1;
                if sections_done < total_sections {
                    json.push_str(",\n");
                } else {
                    json.push_str("\n");
                }
            }

            // Optimization recommendations
            if analyze_optimize {
                analyze_optimizations(&elf, &binary_data, &mut json);
                sections_done += 1;
                if sections_done < total_sections {
                    json.push_str(",\n");
                } else {
                    json.push_str("\n");
                }
            }

            // Startup time profiling
            if analyze_startup {
                analyze_startup_time(&binary_path, &mut json);
                sections_done += 1;
                if sections_done < total_sections {
                    json.push_str(",\n");
                } else {
                    json.push_str("\n");
                }
            }
        }
        Object::Mach(_) => {
            json.push_str("  \"format\": \"Mach-O\",\n");
            json.push_str("  \"error\": \"Mach-O analysis not yet implemented\"\n");
        }
        Object::PE(_) => {
            json.push_str("  \"format\": \"PE\",\n");
            json.push_str("  \"error\": \"PE analysis not yet implemented\"\n");
        }
        _ => {
            json.push_str("  \"format\": \"Unknown\",\n");
            json.push_str("  \"error\": \"Unsupported binary format\"\n");
        }
    }

    json.push_str("}\n");

    // Output JSON
    if let Some(output_path) = output_json {
        fs::write(&output_path, &json).unwrap_or_else(|e| {
            eprintln!("Error writing JSON: {}", e);
            exit(1);
        });
        eprintln!("[ANALYZE] Wrote analysis to: {}", output_path);
    } else {
        println!("{}", json);
    }
}

/// Analyze ELF binary size breakdown by section
///
/// Extracts and aggregates sizes for major ELF sections:
/// - .text: executable code (.init, .fini, .plt included)
/// - .data: initialized data
/// - .rodata: read-only data (constants, string literals)
/// - .bss: uninitialized data (zero-initialized at runtime)
///
/// Outputs JSON with absolute sizes and percentages of total binary size.
fn analyze_elf_size(elf: &goblin::elf::Elf, binary_data: &[u8], json: &mut String) {
    json.push_str("  \"sections\": {\n");

    // Extract section sizes
    let mut text_size = 0u64;
    let mut data_size = 0u64;
    let mut rodata_size = 0u64;
    let mut bss_size = 0u64;

    for section in &elf.section_headers {
        let name = elf.shdr_strtab.get_at(section.sh_name).unwrap_or("");

        match name {
            ".text" | ".init" | ".fini" | ".plt" => {
                text_size += section.sh_size;
            }
            ".data" | ".data1" => {
                data_size += section.sh_size;
            }
            ".rodata" | ".rodata1" => {
                rodata_size += section.sh_size;
            }
            ".bss" => {
                bss_size += section.sh_size;
            }
            _ => {}
        }
    }

    json.push_str("    \"text\": {\n");
    json.push_str(&format!("      \"size\": {},\n", text_size));
    json.push_str(&format!(
        "      \"percentage\": {:.2}\n",
        (text_size as f64 / binary_data.len() as f64) * 100.0
    ));
    json.push_str("    },\n");

    json.push_str("    \"data\": {\n");
    json.push_str(&format!("      \"size\": {},\n", data_size));
    json.push_str(&format!(
        "      \"percentage\": {:.2}\n",
        (data_size as f64 / binary_data.len() as f64) * 100.0
    ));
    json.push_str("    },\n");

    json.push_str("    \"rodata\": {\n");
    json.push_str(&format!("      \"size\": {},\n", rodata_size));
    json.push_str(&format!(
        "      \"percentage\": {:.2}\n",
        (rodata_size as f64 / binary_data.len() as f64) * 100.0
    ));
    json.push_str("    },\n");

    json.push_str("    \"bss\": {\n");
    json.push_str(&format!("      \"size\": {},\n", bss_size));
    json.push_str(&format!(
        "      \"percentage\": {:.2}\n",
        (bss_size as f64 / binary_data.len() as f64) * 100.0
    ));
    json.push_str("    }\n");

    json.push_str("  },\n");

    json.push_str(&format!("  \"total_size\": {}", binary_data.len()));
}

/// Analyze ELF symbol table for optimization opportunities
///
/// Extracts top 20 largest symbols and identifies inlining candidates
/// (functions <64 bytes that might benefit from inlining to reduce call overhead).
///
/// Outputs:
/// - symbols: Top 20 by size with name, address, size, type
/// - inlining_candidates: Functions <64 bytes
fn analyze_elf_symbols(elf: &goblin::elf::Elf, json: &mut String) {
    json.push_str("  \"symbols\": [\n");

    let mut symbols_vec: Vec<_> = elf
        .syms
        .iter()
        .filter(|sym| sym.st_size > 0) // Only symbols with size
        .collect();

    // Sort by size descending
    symbols_vec.sort_by(|a, b| b.st_size.cmp(&a.st_size));

    for (i, sym) in symbols_vec.iter().take(20).enumerate() {
        // Top 20 symbols
        let name = elf.strtab.get_at(sym.st_name).unwrap_or("<unknown>");

        json.push_str("    {\n");
        json.push_str(&format!("      \"name\": \"{}\",\n", name));
        json.push_str(&format!("      \"address\": \"0x{:x}\",\n", sym.st_value));
        json.push_str(&format!("      \"size\": {},\n", sym.st_size));
        json.push_str(&format!(
            "      \"type\": \"{}\"\n",
            match sym.st_info & 0xf {
                0 => "NOTYPE",
                1 => "OBJECT",
                2 => "FUNC",
                3 => "SECTION",
                4 => "FILE",
                _ => "OTHER",
            }
        ));
        json.push_str("    }");
        if i < symbols_vec.len().min(20) - 1 {
            json.push_str(",");
        }
        json.push_str("\n");
    }

    json.push_str("  ],\n");

    // Inlining candidates (small functions < 64 bytes)
    json.push_str("  \"inlining_candidates\": [\n");

    let small_funcs: Vec<_> = elf
        .syms
        .iter()
        .filter(|sym| {
            let is_func = (sym.st_info & 0xf) == 2; // STT_FUNC
            is_func && sym.st_size > 0 && sym.st_size < 64
        })
        .collect();

    for (i, sym) in small_funcs.iter().enumerate() {
        let name = elf.strtab.get_at(sym.st_name).unwrap_or("<unknown>");

        json.push_str("    {\n");
        json.push_str(&format!("      \"name\": \"{}\",\n", name));
        json.push_str(&format!("      \"size\": {}\n", sym.st_size));
        json.push_str("    }");
        if i < small_funcs.len() - 1 {
            json.push_str(",");
        }
        json.push_str("\n");
    }

    json.push_str("  ]");
}

/// Analyze ELF dynamic relocations for performance impact
///
/// Relocations require runtime fixups by the dynamic linker, adding startup overhead.
/// Tracks total count and distribution by relocation type (GOT, PLT, etc.).
///
/// High relocation counts indicate:
/// - Excessive dynamic linking (consider static linking)
/// - Position-independent code overhead
/// - Potential for prelinking or lazy binding optimizations
fn analyze_elf_relocations(elf: &goblin::elf::Elf, json: &mut String) {
    use std::collections::HashMap;

    json.push_str("  \"total_relocations\": ");

    let mut total_relocs = 0usize;
    let mut reloc_types: HashMap<u32, usize> = HashMap::new();

    // Count relocations from all sections
    for rel in &elf.dynrels {
        total_relocs += 1;
        *reloc_types.entry(rel.r_type).or_insert(0) += 1;
    }

    for rel in &elf.pltrelocs {
        total_relocs += 1;
        *reloc_types.entry(rel.r_type).or_insert(0) += 1;
    }

    json.push_str(&format!("{},\n", total_relocs));

    json.push_str("  \"relocation_types\": {\n");
    let mut types_vec: Vec<_> = reloc_types.iter().collect();
    types_vec.sort_by_key(|(_k, v)| std::cmp::Reverse(*v));

    for (i, (rtype, count)) in types_vec.iter().enumerate() {
        json.push_str(&format!("    \"type_{}\": {}", rtype, count));
        if i < types_vec.len() - 1 {
            json.push_str(",");
        }
        json.push_str("\n");
    }
    json.push_str("  }");
}

/// Generate optimization recommendations for binary size reduction
///
/// Analyzes binary characteristics and suggests actionable optimizations:
/// 1. Dead code elimination: Unused functions detected via symbol table
/// 2. Compression: LTO and symbol stripping for large binaries (>1MB)
/// 3. Function outlining: Large functions (>1KB) with cold code paths
///
/// Target: Achieve ≤50% of equivalent C binary size
fn analyze_optimizations(elf: &goblin::elf::Elf, binary_data: &[u8], json: &mut String) {
    json.push_str("  \"recommendations\": [\n");

    let mut recommendations = Vec::new();

    // Check for unused symbols (potential dead code)
    let defined_symbols: Vec<_> = elf
        .syms
        .iter()
        .filter(|sym| {
            let is_defined = sym.st_shndx != 0 && sym.st_shndx < 0xff00;
            let is_func = (sym.st_info & 0xf) == 2;
            is_defined && is_func && sym.st_size > 0
        })
        .collect();

    if defined_symbols.len() > 10 {
        let unused_estimate = defined_symbols.len() / 10; // Rough estimate
        recommendations.push((
            "dead_code_elimination",
            format!(
                "Consider enabling dead code elimination. Estimated {} unused functions.",
                unused_estimate
            ),
            unused_estimate * 100, // Rough bytes estimate
            "high",
        ));
    }

    // Check binary size vs typical sizes
    let binary_size = binary_data.len();
    if binary_size > 1_000_000 {
        // > 1MB
        recommendations.push((
            "compression",
            "Binary size exceeds 1MB. Consider enabling LTO and strip symbols.".to_string(),
            binary_size / 10, // Compression can save ~10%
            "medium",
        ));
    }

    // Check for large functions (candidates for outlining)
    let large_funcs: Vec<_> = elf
        .syms
        .iter()
        .filter(|sym| {
            let is_func = (sym.st_info & 0xf) == 2;
            is_func && sym.st_size > 1024 // Functions > 1KB
        })
        .collect();

    if !large_funcs.is_empty() {
        recommendations.push((
            "function_outlining",
            format!(
                "Found {} large functions (>1KB). Consider outlining cold code paths.",
                large_funcs.len()
            ),
            large_funcs.len() * 200, // Rough estimate
            "medium",
        ));
    }

    // Output recommendations
    for (i, (rec_type, desc, impact, priority)) in recommendations.iter().enumerate() {
        json.push_str("    {\n");
        json.push_str(&format!("      \"type\": \"{}\",\n", rec_type));
        json.push_str(&format!("      \"description\": \"{}\",\n", desc));
        json.push_str(&format!("      \"impact_bytes\": {},\n", impact));
        json.push_str(&format!("      \"priority\": \"{}\"\n", priority));
        json.push_str("    }");
        if i < recommendations.len() - 1 {
            json.push_str(",");
        }
        json.push_str("\n");
    }

    json.push_str("  ]");
}

/// Measure binary startup time and breakdown
///
/// Executes binary with --help flag and measures total startup latency.
/// Provides rough breakdown estimates:
/// - Loader time: Dynamic linker, library loading
/// - Linking time: Symbol resolution, relocations
/// - Init time: Static initializers, constructors
///
/// Note: Breakdown is estimated (equal thirds). Accurate measurement would
/// require instrumentation or LD_DEBUG=statistics.
fn analyze_startup_time(binary_path: &str, json: &mut String) {
    use std::time::Instant;

    // Measure startup time by running the binary with a minimal operation
    let start = Instant::now();
    let _output = Command::new(binary_path)
        .arg("--help") // Many binaries support --help quickly
        .output()
        .ok();
    let startup_time = start.elapsed();

    json.push_str(&format!(
        "  \"startup_time_us\": {},\n",
        startup_time.as_micros()
    ));

    // Break down (rough estimates, would need instrumentation for accuracy)
    let total_us = startup_time.as_micros();
    let loader_est = total_us / 3;
    let linking_est = total_us / 3;
    let init_est = total_us / 3;

    json.push_str(&format!("  \"loader_time_us\": {},\n", loader_est));
    json.push_str(&format!("  \"linking_time_us\": {},\n", linking_est));
    json.push_str(&format!("  \"init_time_us\": {}", init_est));
}
