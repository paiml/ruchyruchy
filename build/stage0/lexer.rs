use std :: collections :: HashMap ; fn tokenize (source : String) -> Vec < String > { { println ! ("\nðŸ”¤ Tokenizing source code...") ; let mut tokens = Vec :: new () ; let mut current = String :: new () ; let mut in_string = false ; let mut chars = source . chars () . collect () ; let mut i = 0i32 ; while i < chars . len () { { { let ch = chars [i as usize] ; { if in_string { { current . push (ch) ; if ch == '"' { { tokens . push (current . clone ()) ; current . clear () ; in_string = false } } } } else { if ch == '"' { { if ! current . is_empty () { { tokens . push (current . clone ()) ; current . clear () } } ; current . push (ch) ; in_string = true } } else { if ch . is_whitespace () { { if ! current . is_empty () { { tokens . push (current . clone ()) ; current . clear () } } } } else { if is_delimiter (ch) { { if ! current . is_empty () { { tokens . push (current . clone ()) ; current . clear () } } ; tokens . push (ch . to_string ()) } } else { { current . push (ch) } } } } } ; i = i + 1i32 } } } } ; if ! current . is_empty () { { tokens . push (current) } } ; println ! ("\nGenerated tokens:") ; for token in & tokens { { println ! ("  Token: '{}'" , token) } } ; tokens } } fn is_delimiter (ch : char) -> bool { { ch == '(' || ch == ')' || ch == '{' || ch == '}' || ch == '[' || ch == ']' || ch == ';' || ch == ',' || ch == '.' || ch == ':' || ch == '=' || ch == '<' || ch == '>' || ch == '+' || ch == '-' || ch == '*' || ch == '/' || ch == '%' || ch == '!' || ch == '&' || ch == '|' || ch == '^' } } fn main () { { println ! ("Stage 0: Lexer - BOOTSTRAP-001 through BOOTSTRAP-004") ; println ! ("=====================================================") ; { let input = format ! ("fn main() {}" , { let mut x = 42i32 ; println ! ("{}" , x) }) ; { println ! ("\nInput: {}" , input) ; let mut tokens = tokenize (input) ; println ! ("\nâœ… Tokenization complete: {} tokens generated" , tokens . len ()) } } } }